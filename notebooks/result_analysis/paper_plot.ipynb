{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/admin-u6015325/ownCloud/git/SynbioML/notebooks/result_analysis\n",
      "['/home/admin-u6015325/ownCloud/git/SynbioML/notebooks/result_analysis', '/home/admin-u6015325/anaconda3/lib/python37.zip', '/home/admin-u6015325/anaconda3/lib/python3.7', '/home/admin-u6015325/anaconda3/lib/python3.7/lib-dynload', '', '/home/admin-u6015325/anaconda3/lib/python3.7/site-packages', '/home/admin-u6015325/anaconda3/lib/python3.7/site-packages/strkernel-0.2-py3.7.egg', '/home/admin-u6015325/anaconda3/lib/python3.7/site-packages/IPython/extensions', '/home/admin-u6015325/.ipython', '/home/admin-u6015325/ownCloud/git/SynbioML']\n"
     ]
    }
   ],
   "source": [
    "# direct to proper path\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm, rcParams\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import json\n",
    "import xarray as xr\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import PairwiseKernel, DotProduct, RBF \n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from codes.embedding import Embedding\n",
    "from codes.environment import Rewards_env\n",
    "from codes.ucb import GPUCB, Random\n",
    "from codes.evaluations import evaluate, plot_eva\n",
    "from codes.regression import *\n",
    "from codes.kernels_for_GPK import *\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcParams['axes.labelsize'] = 10\n",
    "# rcParams['xtick.labelsize'] = 10\n",
    "# rcParams['ytick.labelsize'] = 10\n",
    "# rcParams['legend.fontsize'] = 10\n",
    "# rcParams['font.family'] = 'serif'\n",
    "# rcParams['font.serif'] = ['Computer Modern Roman']\n",
    "# rcParams['text.usetex'] = True\n",
    "\n",
    "# set color\n",
    "color_dict = {}\n",
    "\n",
    "viridis = cm.get_cmap('viridis', 5)\n",
    "tab10 = cm.get_cmap('tab10', 10)\n",
    "\n",
    "color_dict['consensus'] = tab10.colors[1]\n",
    "color_dict['reference'] = tab10.colors[3]\n",
    "color_dict['bps_core'] = tab10.colors[5]\n",
    "color_dict['bps_noncore'] = tab10.colors[6]\n",
    "color_dict['uni random'] = tab10.colors[7]\n",
    "color_dict['prob random'] = tab10.colors[8]\n",
    "color_dict['bandit'] = viridis.colors[0]\n",
    "color_dict['bandit2'] = viridis.colors[1]\n",
    "color_dict['bandit3'] = viridis.colors[2]\n",
    "color_dict['bandit4'] = viridis.colors[3]\n",
    "\n",
    "sns.set_palette(list(color_dict.values())[1:])\n",
    "\n",
    "# generate valids names and path for plots\n",
    "\n",
    "def valid_name(name):\n",
    "    return name.replace('_', ' ')  \n",
    "def valid_path(path):\n",
    "    return path.replace(' ', '_')\n",
    "\n",
    "folder_path = '../../data/pipeline_data/'\n",
    "plot_path = '../../notebooks/paper_plots/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_swarm_flag = False\n",
    "plot_quant_flag = False\n",
    "plot_scatter_flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data\n",
    "\n",
    "Define the following steps on each replicate:  \n",
    "- A. In each round, substract the mean of every data points by the reference AVERAGE, and then add 100 (to make the values positive).  \n",
    "- B. Take log (base e) transformation for each data points.  \n",
    "- C. Apply z-score normalisation.  \n",
    "    - C.1 on all data, so that the mean and variance of each replicate of all data is zero and one after normalisation. \n",
    "    - C.2 on each round, so that the mean and variance of each replicate of data in each round is zero and one after normalisation. \n",
    "- D. Apply min-max normalisation.\n",
    "    - D.1 on all data\n",
    "    - D.2 on each round\n",
    "- E. Apply ratio normalisation. In each round, each data points is devided by the mean of refernce AVERAGE, so that in each round, the reference labels are almost 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "df_e1 = pd.read_csv(folder_path + 'Results_e1.csv')\n",
    "df_abc2 = pd.read_csv(folder_path + 'Results_abc2.csv')\n",
    "df_abc1 = pd.read_csv(folder_path + 'Results_abc1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swarmplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_swarm_flag:\n",
    "    f, axes = plt.subplots(1, 1, figsize=(10, 6), sharex=False)\n",
    "    sns.swarmplot(x = 'Group', y = 'AVERAGE', data = df_e1, ax = axes, order=['Reference', 'BPS-NC', 'BPS-C', 'UNI', 'PPM', 'Bandit-0', 'Bandit-1', 'Bandit-2', 'Bandit-3'])\n",
    "    y = df_e1[df_e1['Group'] == 'Consensus']['AVERAGE']\n",
    "    axes.scatter(x = 0, y = y, color = color_dict['consensus'])\n",
    "    axes.text(0, y + 0.05, 'SD')\n",
    "    axes.set(xlabel='Sequence design principles', ylabel='Translation Initiation Rate (TIR),\\\\ averaged over 6 technical replicates')\n",
    "    axes.set_title('Swarmplot with TIR Labels (ratio)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_path + 'swarmplot.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantile plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def quant_line(df, col = 'Group', title = 'Quantile of groups'):\n",
    "    f, axes = plt.subplots(1, 1, figsize=(10, 6), sharex=False)\n",
    "    quantile_levels = [0.9, 0.8, 0.7, 0.6, 0.5]\n",
    "    used_groups = ['BPS-C', 'Random', 'Bandit-0', 'Bandit-1', 'Bandit-2', 'Bandit-3']\n",
    "    df_bandits = df.loc[df[col].isin(used_groups)]\n",
    "\n",
    "    quant_dict = defaultdict(list)\n",
    "    groups = df_bandits.groupby(col)\n",
    "    \n",
    "\n",
    "    for used_group in used_groups:\n",
    "        quant_dict['max'].append(groups.get_group(used_group)['AVERAGE'].max())\n",
    "    axes.plot(range(len(used_groups)), quant_dict['max'], marker = '.', label = 'max', alpha = 0.8, color = 'orange')\n",
    "\n",
    "    for quant in quantile_levels:\n",
    "        for used_group in used_groups:\n",
    "            quant_dict[quant].append(groups.get_group(used_group)['AVERAGE'].quantile(quant))\n",
    "        axes.plot(range(len(used_groups)), quant_dict[quant], marker = '.', label = str(quant), alpha = 0.8)\n",
    " \n",
    "    # plt.plot(df_bandits.sort_values('AVERAGE',ascending=False).groupby(col).nth(4)['AVERAGE'], marker = '.', label = 'Top-5', alpha = 0.6)\n",
    "    plt.legend()\n",
    "    plt.xticks(range(len(used_groups)), used_groups)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_path + 'quantplot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_e1['Group2'] = df_e1['Group']\n",
    "df_e1.loc[df_e1['Group2'] == 'UNI', 'Group2'] = 'Random'\n",
    "df_e1.loc[df_e1['Group2'] == 'PPM', 'Group2'] = 'Random'\n",
    "\n",
    "if plot_quant_flag:\n",
    "    sns.set_palette('viridis') \n",
    "    quant_line(df_e1, 'Group2')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy from the pipeline for recommending round 2 seq\n",
    "from codes.batch_ucb import *\n",
    "from codes.regression import *\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "rec_size = 90\n",
    "l = 6\n",
    "s = 1\n",
    "beta = 0\n",
    "alpha = 2\n",
    "sigma_0 = 1\n",
    "kernel = 'WD_Kernel_Shift'\n",
    "embedding = 'label'\n",
    "kernel_norm_flag = True\n",
    "\n",
    "sns.set_palette('tab10') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regression(df,kernel, embedding, predictor = GPR_Predictor, train_idx = None, test_idx = None, \n",
    "                    eva_metric = [mean_squared_error, r2_score], l = 6, s = 1, sigma_0=1, alpha = 2, \n",
    "                    eva_on='seqs', title = 'Prediction',\n",
    "                    kernel_norm_flag = True, centering_flag = False, unit_norm_flag = True):\n",
    "    title = title + ' centering' + str(centering_flag) + 'unitnorm' + str(unit_norm_flag)\n",
    "    # train and test on round 0\n",
    "    gpr_train_samples = predictor(df, train_idx= train_idx, test_idx=test_idx, kernel_name = kernel,\n",
    "                kernel_norm_flag = kernel_norm_flag, centering_flag = centering_flag, unit_norm_flag = unit_norm_flag,\n",
    "                embedding = embedding, eva_metric = eva_metric, l = l, s = s, sigma_0 = sigma_0, alpha = alpha, eva_on=eva_on)\n",
    "    gpr_train_samples.regression(random_state = 0)\n",
    "\n",
    "    return gpr_train_samples\n",
    "    # gpr_train_samples.scatter_plot(title = title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(predictor_list, title, plot_title = 'Prediction'):\n",
    "        \"\"\"Scatter plot for predictions.\n",
    "        x-axis: label\n",
    "        y-axis: prediction\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(1,4, figsize = (20,6))\n",
    "        for i, predictor in enumerate(predictor_list):\n",
    "            if predictor.eva_on == 'samples':\n",
    "                eva_column = 'label'\n",
    "            else:\n",
    "                eva_column = 'AVERAGE'\n",
    "\n",
    "            # if eva_column == 'AVERAGE': # debug\n",
    "            #     self.train_df = self.train_df[self.train_df['variable'] == 'Rep1']\n",
    "            print('#################################')\n",
    "            print('  Evaluation  ', title[i])\n",
    "            print('#################################')\n",
    "            for metric in predictor.eva_metric:\n",
    "                print(str(metric))\n",
    "                print('Train: ', metric(predictor.train_df[eva_column], predictor.train_df['pred mean']))\n",
    "                print('Test: ', metric(predictor.test_df[eva_column], predictor.test_df['pred mean']))\n",
    "\n",
    "            print('spearman cor:')\n",
    "            print('Train: ', spearmanr(predictor.train_df[eva_column], predictor.train_df['pred mean']))\n",
    "            test_spearmanr = spearmanr(predictor.test_df[eva_column], predictor.test_df['pred mean'])\n",
    "            print('Test: ', test_spearmanr.correlation, ' ', test_spearmanr.pvalue)\n",
    "\n",
    "            # report slope\n",
    "            test_pred_fit = np.polyfit(x = range(len(predictor.test_df)), y=predictor.test_df.sort_values(by = ['AVERAGE'])['pred mean'],deg=1)\n",
    "            test_ave_fit = np.polyfit(x = range(len(predictor.test_df)), y=predictor.test_df.sort_values(by = ['AVERAGE'])['AVERAGE'],deg=1)\n",
    "            print('Test pred fit: ', test_pred_fit)\n",
    "            print('Test ave fit: ', test_ave_fit)\n",
    "            \n",
    "            if 'pred std' in predictor.test_df:\n",
    "                print('coverage rate: ')\n",
    "                print('Train: ',  predictor.coverage_rate(predictor.train_df[eva_column], predictor.train_df['pred mean'], predictor.train_df['pred std']))\n",
    "                print('Test: ',  predictor.coverage_rate(predictor.test_df[eva_column], predictor.test_df['pred mean'], predictor.test_df['pred std']))\n",
    "\n",
    "            axes[i].scatter(predictor.train_df[eva_column], predictor.train_df['pred mean'], label = 'train', alpha = 0.2)\n",
    "            axes[i].scatter(predictor.test_df[eva_column], predictor.test_df['pred mean'], label = 'test', alpha = 0.8)\n",
    "            axes[i].set_xlabel('True TIR')\n",
    "            axes[i].set_ylabel('Predict TIR')\n",
    "            axes[i].legend()\n",
    "            axes[i].plot([-2, 3], [-2,3], '--', color = 'black', alpha = 0.5)\n",
    "            axes[i].set_title('\\n' + title[i] + \n",
    "                ' R2 = ' + str(\"{:.3f}\".format(r2_score(predictor.test_df[eva_column], predictor.test_df['pred mean']))) + \n",
    "                '\\n Spearman cor = ' + str(\"{:.3f}\".format(test_spearmanr.correlation)) + ' pvalue: ' + str(\"{:.2e}\".format(test_spearmanr.pvalue))\n",
    "                )\n",
    "\n",
    "        fig.suptitle(plot_title, size = 16, y = 0.98)\n",
    "        fig.tight_layout()\n",
    "        fig.subplots_adjust(top=0.85)\n",
    "        fig.savefig(plot_path + 'scatter_' + valid_path(plot_title) + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictors(df, kernel, embedding, kernel_norm_flag = True, centering_flag = True, unit_norm_flag = True):\n",
    "    predictors = []\n",
    "    for i in range(1,4):\n",
    "        title = 'Train < ' + str(i)+ ' and Test ' + str(i)\n",
    "        predictor = run_regression(df, kernel, embedding, train_idx = df['Round'] < i, test_idx = df['Round'] == i, title = title, centering_flag=centering_flag, unit_norm_flag=unit_norm_flag)\n",
    "        predictors.append(predictor)\n",
    "\n",
    "    predictor = run_regression(df, kernel, embedding, title = 'Train and Test on All Rounds', centering_flag=centering_flag, unit_norm_flag=unit_norm_flag)\n",
    "    predictors.append(predictor)\n",
    "    return predictors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_scatter_flag:\n",
    "    centering_flag = True\n",
    "    unit_norm_flag = True\n",
    "    df_abc1_TT_predictors = generate_predictors(df_abc1, kernel, embedding, centering_flag, unit_norm_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_scatter_flag:\n",
    "    scatter_plot(df_abc1_TT_predictors, ['train 0 test 1', 'train 01 test 2', 'train 012 test 3', 'train test all'], 'abc1 TT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_scatter_flag:\n",
    "    centering_flag = False\n",
    "    unit_norm_flag = False\n",
    "\n",
    "    df_abc1_FF_predictors = generate_predictors(df_abc1, kernel, embedding, centering_flag, unit_norm_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_scatter_flag:\n",
    "    scatter_plot(df_abc1_FF_predictors, \n",
    "                ['train 0 test 1', 'train 01 test 2', 'train 012 test 3', 'train test all'], 'abc1 FF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_scatter_flag:\n",
    "    centering_flag = True\n",
    "    unit_norm_flag = True\n",
    "    df_abc2_TT_predictors = generate_predictors(df_abc2, kernel, embedding, centering_flag, unit_norm_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_scatter_flag:\n",
    "    scatter_plot(df_abc2_TT_predictors, ['train 0 test 1', 'train 01 test 2', 'train 012 test 3', 'train test all'], 'abc2 TT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_scatter_flag:\n",
    "    centering_flag = False\n",
    "    unit_norm_flag = False\n",
    "    df_abc2_FF_predictors = generate_predictors(df_abc2, kernel, embedding, centering_flag, unit_norm_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_scatter_flag:\n",
    "    scatter_plot(df_abc2_FF_predictors, ['train 0 test 1', 'train 01 test 2', 'train 012 test 3', 'train test all'], 'abc2 FF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confirm rec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codes.batch_ucb import *\n",
    "\n",
    "centering_flag = False\n",
    "unit_norm_flag = True\n",
    "rec_size = 90\n",
    "beta = 2\n",
    "\n",
    "rec_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin-u6015325/ownCloud/git/SynbioML/codes/batch_ucb.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_known['train_test'] = 'Train'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape:  (1055, 20)\n",
      "X test shape:  (3961, 20)\n",
      "create kernel instance\n",
      "wds_l6_sigma0_1_s1_center_False_unitnorm_True\n",
      "Load saved kernel matrix...\n",
      "finish creating kernel instance\n",
      "gp_reg fit\n",
      "wds_l6_sigma0_1_s1_center_False_unitnorm_True\n",
      "Load saved kernel matrix...\n",
      "wds_l6_sigma0_1_s1_center_False_unitnorm_True\n",
      "Load saved kernel matrix...\n",
      "gp_reg pred\n",
      "finish reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin-u6015325/ownCloud/git/SynbioML/codes/batch_ucb.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_known['train_test'] = 'Train'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape:  (1589, 20)\n",
      "X test shape:  (3873, 20)\n",
      "create kernel instance\n",
      "wds_l6_sigma0_1_s1_center_False_unitnorm_True\n",
      "Load saved kernel matrix...\n",
      "finish creating kernel instance\n",
      "gp_reg fit\n",
      "wds_l6_sigma0_1_s1_center_False_unitnorm_True\n",
      "Load saved kernel matrix...\n",
      "wds_l6_sigma0_1_s1_center_False_unitnorm_True\n",
      "Load saved kernel matrix...\n",
      "gp_reg pred\n",
      "finish reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin-u6015325/ownCloud/git/SynbioML/codes/batch_ucb.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_known['train_test'] = 'Train'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape:  (2147, 20)\n",
      "X test shape:  (3783, 20)\n",
      "create kernel instance\n",
      "wds_l6_sigma0_1_s1_center_False_unitnorm_True\n",
      "Load saved kernel matrix...\n",
      "finish creating kernel instance\n",
      "gp_reg fit\n",
      "wds_l6_sigma0_1_s1_center_False_unitnorm_True\n",
      "Load saved kernel matrix...\n",
      "wds_l6_sigma0_1_s1_center_False_unitnorm_True\n",
      "Load saved kernel matrix...\n",
      "gp_reg pred\n",
      "finish reg\n"
     ]
    }
   ],
   "source": [
    "for i in [1,2,3]:\n",
    "    if i == 3:\n",
    "        beta = 0\n",
    "\n",
    "    top_n = Top_n_ucb(df_abc1[df_abc1['Round'] < i], kernel_name=kernel, l=l, s=s, sigma_0=sigma_0,\n",
    "                    embedding=embedding, alpha=alpha, rec_size=rec_size, beta=beta, \n",
    "                    kernel_norm_flag=kernel_norm_flag, centering_flag = centering_flag,              unit_norm_flag=unit_norm_flag)\n",
    "\n",
    "    top_n_rec_df = top_n.run_experiment()\n",
    "    rec_dict[i] = top_n_rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "43\n",
      "2\n",
      "32\n",
      "3\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "for i, df in rec_dict.items():\n",
    "    new_rec = set(np.asarray(df['RBS6']))\n",
    "    lib_rec = set(np.asarray(df_abc1[df_abc1['Round'] == i]['RBS6']))\n",
    "    num_overlap = len(new_rec.intersection(lib_rec))\n",
    "    print(i)\n",
    "    print(num_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin-u6015325/ownCloud/git/SynbioML/codes/batch_ucb.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_known['train_test'] = 'Train'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape:  (1055, 20)\n",
      "X test shape:  (3961, 20)\n",
      "create kernel instance\n",
      "wds_l6_sigma0_1_s1_center_True_unitnorm_True\n",
      "Load saved kernel matrix...\n",
      "finish creating kernel instance\n",
      "gp_reg fit\n",
      "wds_l6_sigma0_1_s1_center_True_unitnorm_True\n",
      "Load saved kernel matrix...\n",
      "wds_l6_sigma0_1_s1_center_True_unitnorm_True\n",
      "Load saved kernel matrix...\n",
      "gp_reg pred\n",
      "finish reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin-u6015325/ownCloud/git/SynbioML/codes/batch_ucb.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_known['train_test'] = 'Train'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape:  (1589, 20)\n",
      "X test shape:  (3873, 20)\n",
      "create kernel instance\n",
      "wds_l6_sigma0_1_s1_center_True_unitnorm_True\n",
      "Load saved kernel matrix...\n",
      "finish creating kernel instance\n",
      "gp_reg fit\n",
      "wds_l6_sigma0_1_s1_center_True_unitnorm_True\n",
      "Load saved kernel matrix...\n",
      "wds_l6_sigma0_1_s1_center_True_unitnorm_True\n",
      "Load saved kernel matrix...\n",
      "gp_reg pred\n",
      "finish reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin-u6015325/ownCloud/git/SynbioML/codes/batch_ucb.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_known['train_test'] = 'Train'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape:  (2147, 20)\n",
      "X test shape:  (3783, 20)\n",
      "create kernel instance\n",
      "wds_l6_sigma0_1_s1_center_True_unitnorm_True\n",
      "Load saved kernel matrix...\n",
      "finish creating kernel instance\n",
      "gp_reg fit\n",
      "wds_l6_sigma0_1_s1_center_True_unitnorm_True\n",
      "Load saved kernel matrix...\n",
      "wds_l6_sigma0_1_s1_center_True_unitnorm_True\n",
      "Load saved kernel matrix...\n",
      "gp_reg pred\n",
      "finish reg\n"
     ]
    }
   ],
   "source": [
    "centering_flag = True\n",
    "unit_norm_flag = True\n",
    "rec_size = 90\n",
    "beta = 2\n",
    "\n",
    "abc1TT_rec_dict = {}\n",
    "\n",
    "for i in [1,2,3]:\n",
    "    if i == 3:\n",
    "        beta = 0\n",
    "\n",
    "    top_n = Top_n_ucb(df_abc1[df_abc1['Round'] < i], kernel_name=kernel, l=l, s=s, sigma_0=sigma_0,\n",
    "                    embedding=embedding, alpha=alpha, rec_size=rec_size, beta=beta, \n",
    "                    kernel_norm_flag=kernel_norm_flag, centering_flag = centering_flag,              unit_norm_flag=unit_norm_flag)\n",
    "\n",
    "    top_n_rec_df = top_n.run_experiment()\n",
    "    abc1TT_rec_dict[i] = top_n_rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "70\n",
      "2\n",
      "74\n",
      "3\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "for i, df in abc1TT_rec_dict.items():\n",
    "    new_rec = set(np.asarray(df['RBS6']))\n",
    "    lib_rec = set(np.asarray(df_abc1[df_abc1['Round'] == i]['RBS6']))\n",
    "    num_overlap = len(new_rec.intersection(lib_rec))\n",
    "    print(i)\n",
    "    print(num_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
